{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import import_ipynb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from utils import data\n",
    "from models import BiLSTM_CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils.data' has no attribute 'json_to_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d7adb649b686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m              'B_scene':21, 'I_scene':22}\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson_to_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/train.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_to_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mNER_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNER_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold_cross_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNER_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'utils.data' has no attribute 'json_to_input'"
     ]
    }
   ],
   "source": [
    "tag_to_ix = {'START_TAG':0, 'STOP_TAG':1, 'O':2,\n",
    "             'B_address':3, 'I_address':4,\n",
    "             'B_book':5, 'I_book':6, \n",
    "             'B_company':7, 'I_company':8, \n",
    "             'B_game':9, 'I_game':10, \n",
    "             'B_government':11, 'I_government':12,\n",
    "             'B_movie':13, 'I_movie':14, \n",
    "             'B_name':15, 'I_name':16, \n",
    "             'B_organization':17, 'I_organization':18, \n",
    "             'B_position':19, 'I_position':20, \n",
    "             'B_scene':21, 'I_scene':22}\n",
    "\n",
    "data = data.json_to_input('../data/train.json', tag_to_ix)\n",
    "NER_dataset = data.NER_Dataset(data)\n",
    "train_loader, valid_loader = kfold_cross_data(NER_dataset, 10, 0)\n",
    "word_to_ix = gen_Vocab(train_loader)\n",
    "vocab_size = len(word_to_ix)\n",
    "print(vocab_size)\n",
    "embedding_dim = 128\n",
    "word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "for data in train_loader:\n",
    "    s, l = data\n",
    "    s = sentence_to_ix(s, word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
